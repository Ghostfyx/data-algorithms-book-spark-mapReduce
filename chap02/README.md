## MR与Spark框架实现二次排序思想
MapReduce框架会按照键对Reducer的输入排序，但是Value是无序的。在默认情况下我们需要将Reducer的所有Value加载在内存中进行排序（例如：快速排序等），这样会导致计算速度变慢，硬件资源浪费以及大数据情况下的内存溢出。

那么我们如何利用MapReduce框架进行二次排序呢？由于MR框架对Reducer输入的键进行排序，因此我们需要：
    1. 将原有自然键与需要排序值组成组合键，定义组合键排序方式即可。
    2. 对于新的组合键，我们需要自定制分区器和定制比较器，定制分区器决定Mapper的输出的键(自然键)映射到的Reducer；定制比较器会完成键（组合键）的排序；
    3. 定制分组比较器，分区器将具有相同键（自然键）的数据到同一个Reduce，而分组比较器决定哪些键（自然键）到一个Reduce.reduce()函数调用，
## stockSymbol input data
~~~
<stockSymbol><,><data><close-price>
~~~